{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6225f925-b124-4075-a8ce-a4d7d8add7bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:49.886826100Z",
     "start_time": "2024-05-22T20:47:49.829932700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data.dataset import SkinDataset, NonSkinDataset\n",
    "from settings import *\n",
    "from utils.data_augmentation import *\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "380b5918-58cb-46a0-969f-6b7a15318fee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:49.977874Z",
     "start_time": "2024-05-22T20:47:49.834938700Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d555efbfc0937a04",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:50.507394800Z",
     "start_time": "2024-05-22T20:47:49.846307500Z"
    }
   },
   "outputs": [],
   "source": [
    "skin_file_paths = collect_file_paths(os.path.join(DATA_DIR, \"SKIN\"))\n",
    "not_skin_file_paths = collect_file_paths(os.path.join(DATA_DIR, \"NS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "450994f4-1f4d-4ffe-9f49-2690fb978608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:51.193566500Z",
     "start_time": "2024-05-22T20:47:50.505396600Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "skin_indices = torch.randperm(len(skin_file_paths))\n",
    "skin_file_paths = [skin_file_paths[i] for i in skin_indices]\n",
    "\n",
    "not_skin_indices = torch.randperm(len(not_skin_file_paths))\n",
    "not_skin_file_paths = [not_skin_file_paths[i] for i in not_skin_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96cf2188-57f7-4590-a6b0-efbecc97a850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:51.205786300Z",
     "start_time": "2024-05-22T20:47:51.197564400Z"
    }
   },
   "outputs": [],
   "source": [
    "train_skin_file_paths = skin_file_paths[:NUM_TRAIN_SKIN]\n",
    "train_not_skin_file_paths = not_skin_file_paths[:NUM_TRAIN_NOT_SKIN]\n",
    "\n",
    "test_skin_file_paths = skin_file_paths[NUM_TRAIN_SKIN:NUM_TRAIN_SKIN + NUM_TEST_SKIN]\n",
    "test_not_skin_file_paths = not_skin_file_paths[NUM_TRAIN_NOT_SKIN:\n",
    "                                               NUM_TRAIN_NOT_SKIN + NUM_TEST_NOT_SKIN]\n",
    "\n",
    "val_skin_file_paths = skin_file_paths[NUM_TRAIN_SKIN + NUM_TEST_SKIN:]\n",
    "val_not_skin_file_paths = not_skin_file_paths[NUM_TRAIN_NOT_SKIN +\n",
    "                                              NUM_TEST_NOT_SKIN:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8452747a-b425-4f56-a2b1-163aa2fe90f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:51.232006900Z",
     "start_time": "2024-05-22T20:47:51.206786400Z"
    }
   },
   "outputs": [],
   "source": [
    "train_skin_dataset = SkinDataset(train_skin_file_paths)\n",
    "train_not_skin_dataset = NonSkinDataset(train_not_skin_file_paths)\n",
    "\n",
    "test_skin_dataset = SkinDataset(test_skin_file_paths)\n",
    "test_not_skin_dataset = NonSkinDataset(test_not_skin_file_paths)\n",
    "\n",
    "val_skin_dataset = SkinDataset(val_skin_file_paths)\n",
    "val_not_skin_dataset = NonSkinDataset(val_not_skin_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "358ec2c4-c260-4d74-895d-94df219c7543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:51.233007100Z",
     "start_time": "2024-05-22T20:47:51.219479500Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = ConcatDataset([train_skin_dataset, train_not_skin_dataset])\n",
    "test_dataset = ConcatDataset([test_skin_dataset, test_not_skin_dataset])\n",
    "val_dataset = ConcatDataset([val_skin_dataset, val_not_skin_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ee9c483-920a-40b3-87a1-59b38b631ed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:51.243752400Z",
     "start_time": "2024-05-22T20:47:51.230007100Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc9aeccd-26ff-4309-8a0d-8417bad06b95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:51.260660200Z",
     "start_time": "2024-05-22T20:47:51.242752800Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=16, kernel_size=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=32, kernel_size=2, stride=1)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=1, stride=1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 17 * 17, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # print(\"After conv1\", x.shape)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # print(\"After conv2\", x.shape)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        # print(\"After conv3\", x.shape)\n",
    "        x = self.maxpool(x)\n",
    "        # print(\"After maxpool2d\", x.shape)\n",
    "        x = self.flatten(x)\n",
    "        # print(\"After flatten\", x.shape)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        # print(\"After fc1\", x.shape)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        # print(\"After fc2\", x.shape)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e24cebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:51.293624800Z",
     "start_time": "2024-05-22T20:47:51.262667Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_cnn(train_loader, val_loader, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, save_path='model/model.pth'):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CNN().to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        # Create a tqdm progress bar for training\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit='batch') as pbar:\n",
    "            for _, (inputs, targets) in enumerate(train_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                targets = targets.float().view(-1, 1)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                pbar.update(1)\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Average Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            # Create a tqdm progress bar for validation\n",
    "            with tqdm(total=len(val_loader), desc=f\"Validation Epoch {epoch+1}/{num_epochs}\", unit='batch') as pbar:\n",
    "                for val_inputs, val_targets in val_loader:\n",
    "                    val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                    val_outputs = model(val_inputs)\n",
    "                    val_loss += criterion(val_outputs, val_targets).item()\n",
    "                    pbar.update(1)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Save the model after each epoch\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbbd927a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:51.293624800Z",
     "start_time": "2024-05-22T20:47:51.269828600Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b13f4b2-305a-4382-bf40-02fbf353b8c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:51.294622Z",
     "start_time": "2024-05-22T20:47:51.273834200Z"
    }
   },
   "outputs": [],
   "source": [
    "# def train_cnn(train_loader, val_loader, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE):\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model = CNN().to(device)\n",
    "#     criterion = nn.BCELoss()\n",
    "#     optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         total_loss = 0.0\n",
    "#         for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             targets = targets.float().view(-1, 1)\n",
    "#             print(targets.shape, outputs.shape)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#         avg_loss = total_loss / len(train_loader)\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             val_loss = 0.0\n",
    "#             for val_inputs, val_targets in val_loader:\n",
    "#                 val_inputs, val_targets = val_inputs.to(\n",
    "#                     device), val_targets.to(device)\n",
    "#                 val_outputs = model(val_inputs)\n",
    "#                 val_loss += criterion(val_outputs, val_targets).item()\n",
    "\n",
    "#             avg_val_loss = val_loss / len(val_loader)\n",
    "#             print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "#     print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fcac1e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:47:51.294622Z",
     "start_time": "2024-05-22T20:47:51.280105Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66703c-abbe-4055-b8ea-43691d7d62b9",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-22T20:47:51.284624300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  82%|████████▏ | 804/983 [1:17:59<49:21, 16.54s/batch, loss=0.189]    "
     ]
    }
   ],
   "source": [
    "train_cnn(train_loader=train_loader, val_loader=val_loader,\n",
    "          batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03f2e8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skin-detection-kernel",
   "language": "python",
   "name": "skin-detection-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
